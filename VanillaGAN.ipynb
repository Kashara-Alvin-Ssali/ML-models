{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kashara-Alvin-Ssali/ML-models/blob/main/VanillaGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RTQafmx_j47"
      },
      "outputs": [],
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNOA0hH6_uIw",
        "outputId": "386d8f4e-afc2-4abf-8d8f-8617b791ad06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib\n",
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUxMiZFI_v-c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWDBWtRg_yxG"
      },
      "outputs": [],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9WWm-F1_0yg"
      },
      "outputs": [],
      "source": [
        "# # Data Preprocessing (Modified for 256x256 images)\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((256, 256)),  # Resize images to 256x256\n",
        "#     transforms.ToTensor(),        # Convert to tensor\n",
        "#     transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPKb-HnK_2_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a35c059-2dfb-43bb-d219-41626e9cc18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Specify dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Dataset4\"  # Path to your dataset folder in Drive\n",
        "\n",
        "# 3. Data Preprocessing (Modified for 256x256 images)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
        "    transforms.ToTensor(),        # Convert to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# 4. Create dataset and dataloader\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nja4e7Mc_5MS"
      },
      "outputs": [],
      "source": [
        "# Define Generator (Modified for 256x256 images)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 256 * 256 * 3),  # Output for 256x256 images\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        output = self.main(z)\n",
        "        # Reshape and upsample\n",
        "        output = output.view(-1, 3, 256, 256)  # Reshape for 256x256\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfG0hDHN_7f8"
      },
      "outputs": [],
      "source": [
        "# Define Discriminator (Modified for 256x256 images)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(256 * 256 * 3, 1024),  # Input for 256x256 images\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        return self.main(img_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkI_pRtx_-YD"
      },
      "outputs": [],
      "source": [
        "# Define FGSM attack function\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxJVV6X7AAq5"
      },
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFFyxg_BAC4W"
      },
      "outputs": [],
      "source": [
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUkvaUYLAEx9"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n5za5njAHK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d0d499-8422-413c-8bcc-f9fa25073319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] | D Loss: 5.2612 | G Loss: 0.0192\n",
            "Epoch [2/50] | D Loss: 1.1051 | G Loss: 0.8174\n",
            "Epoch [3/50] | D Loss: 1.1987 | G Loss: 0.9690\n",
            "Epoch [4/50] | D Loss: 2.2747 | G Loss: 0.1961\n",
            "Epoch [5/50] | D Loss: 2.0314 | G Loss: 0.2203\n",
            "Epoch [6/50] | D Loss: 2.4930 | G Loss: 1.2456\n",
            "Epoch [7/50] | D Loss: 1.4488 | G Loss: 0.2336\n",
            "Epoch [8/50] | D Loss: 1.7991 | G Loss: 0.3156\n",
            "Epoch [9/50] | D Loss: 0.4593 | G Loss: 1.2052\n",
            "Epoch [10/50] | D Loss: 7.2327 | G Loss: 0.0305\n",
            "Epoch [11/50] | D Loss: 0.6467 | G Loss: 0.9491\n",
            "Early stopping triggered at epoch 11.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Ensure 'generated_images' directory exists\n",
        "os.makedirs(\"generated_images\", exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "epsilon = 0.001  # FGSM attack strength\n",
        "patience = 10  # Early stopping patience\n",
        "early_stop_counter = 0\n",
        "best_g_loss = float('inf')\n",
        "\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    \"\"\"Generate adversarial example using FGSM attack.\"\"\"\n",
        "    perturbed_image = image + epsilon * data_grad.sign()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)  # Keep image valid\n",
        "    return perturbed_image\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        real_imgs = imgs.to(device)\n",
        "        real_labels = torch.ones(1, 1).to(device)\n",
        "        fake_labels = torch.zeros(1, 1).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_imgs.requires_grad = True\n",
        "        outputs = discriminator(real_imgs)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        d_loss_real.backward(retain_graph=True)\n",
        "        data_grad = real_imgs.grad.data\n",
        "        perturbed_data = fgsm_attack(real_imgs, epsilon, data_grad)\n",
        "\n",
        "        outputs = discriminator(perturbed_data)\n",
        "        d_loss_adv = criterion(outputs, real_labels)\n",
        "        d_loss_adv.backward()\n",
        "\n",
        "        # Train on fake images\n",
        "        z = torch.randn(1, 100).to(device)\n",
        "        fake_imgs = generator(z)\n",
        "        outputs = discriminator(fake_imgs.detach())\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        outputs = discriminator(fake_imgs)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    total_d_loss = (d_loss_real + d_loss_adv + d_loss_fake).item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] | D Loss: {total_d_loss:.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Save generated images every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        vutils.save_image(fake_imgs, f\"generated_images/epoch_{epoch}_image.png\", normalize=True)\n",
        "\n",
        "    # Early stopping logic\n",
        "    if g_loss.item() < best_g_loss:\n",
        "        best_g_loss = g_loss.item()\n",
        "        early_stop_counter = 0\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        if early_stop_counter >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPNnDOeIwcoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88bbFFgAwg63"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3h/aYxJBHWzIGc6A8Yfqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}