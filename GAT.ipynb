{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj04y5MTmnZk22nAO/IeBJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kashara-Alvin-Ssali/ML-models/blob/main/GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio torch-geometric networkx scipy numpy opencv-python matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP9b2jZctNGW",
        "outputId": "7f2a3812-dbb9-45d1-bbf8-5c0a92a550ac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bocuzyG9r0wH",
        "outputId": "2b58b537-b8ff-488d-8acd-806baf2c8f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy.spatial import Delaunay\n",
        "import torch\n",
        "from torch_geometric.data import Data, Dataset, DataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "qwnNjKvNr870"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path in Google Drive\n",
        "dataset_path = \"/content/drive/MyDrive/Dataset4\""
      ],
      "metadata": {
        "id": "AdjNKsONr_M5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert image to graph using ORB + Delaunay Triangulation\n",
        "def computeORBGraph(image):\n",
        "    \"\"\"\n",
        "    Extracts keypoints from an image using ORB and constructs a graph representation.\n",
        "    Nodes represent keypoints, and edges are formed using Delaunay Triangulation.\n",
        "    \"\"\"\n",
        "    orb = cv2.ORB_create(nfeatures=700, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
        "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
        "\n",
        "    if not keypoints or descriptors is None:\n",
        "        return None, None, None  # No keypoints detected\n",
        "\n",
        "    points = np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with descriptors\n",
        "    for i, (x, y) in enumerate(points):\n",
        "        G.add_node(i, pos=(x, y), descriptor=descriptors[i])\n",
        "\n",
        "    # Create edges using Delaunay Triangulation\n",
        "    if len(points) > 2:\n",
        "        tri = Delaunay(points)\n",
        "        for simplex in tri.simplices:\n",
        "            for i in range(3):\n",
        "                G.add_edge(simplex[i], simplex[(i+1) % 3])\n",
        "\n",
        "    return G, keypoints, descriptors\n"
      ],
      "metadata": {
        "id": "naAkm0wSsBdu"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom PyTorch Geometric Dataset for Currency Notes\n",
        "class CurrencyGraphDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        self.data_list = [] # Initialize data_list here, before calling super().__init__\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.process()\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        \"\"\"\n",
        "        Returns a list of filenames that represent the processed dataset.\n",
        "        This is required by the PyTorch Geometric Dataset class to check if the\n",
        "        data has already been processed.\n",
        "        \"\"\"\n",
        "        return ['data.pt']  # You can change this to a more descriptive name or a list of files if needed.\n",
        "\n",
        "    def process(self):\n",
        "        for label, folder in enumerate(['Real', 'Fake']):\n",
        "            folder_path = os.path.join(dataset_path, 'Training', folder)\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                G, keypoints, descriptors = computeORBGraph(image)\n",
        "                if G is None:\n",
        "                    continue\n",
        "\n",
        "                # Convert graph to PyTorch Geometric format\n",
        "                edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
        "                x = torch.tensor(np.array([G.nodes[i]['descriptor'] for i in G.nodes]), dtype=torch.float)\n",
        "                y = torch.tensor([label], dtype=torch.long)  # Graph-level label\n",
        "\n",
        "                data = Data(x=x, edge_index=edge_index, y=y)\n",
        "                self.data_list.append(data)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def get(self, idx):\n",
        "        return self.data_list[idx]"
      ],
      "metadata": {
        "id": "5663pgArsJmC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = CurrencyGraphDataset(root=dataset_path)\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "print(f\"Loaded {len(dataset)} graphs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrwgUEBNsKUG",
        "outputId": "80cbbfde-817f-4860-ac90-b0fc3bac4f57"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 128 graphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "# Define the GAT model\n",
        "class GATClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, output_dim=2, heads=2):\n",
        "        super(GATClassifier, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, data.batch)  # Graph-level pooling\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Get feature dimension from dataset\n",
        "input_dim = dataset[0].x.shape[1]\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GATClassifier(input_dim=input_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.NLLLoss()\n"
      ],
      "metadata": {
        "id": "Ao96m37IsM34"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, criterion, epochs=50):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Train for 50 epochs\n",
        "train_model(model, train_loader, optimizer, criterion, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53T4BjhTsP-4",
        "outputId": "0232e9b0-04e6-49c7-c493-af8d47f610be"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 134.2351\n",
            "Epoch 2/50, Loss: 31.5559\n",
            "Epoch 3/50, Loss: 26.1116\n",
            "Epoch 4/50, Loss: 26.0522\n",
            "Epoch 5/50, Loss: 24.8720\n",
            "Epoch 6/50, Loss: 23.3207\n",
            "Epoch 7/50, Loss: 21.1386\n",
            "Epoch 8/50, Loss: 20.6330\n",
            "Epoch 9/50, Loss: 19.7171\n",
            "Epoch 10/50, Loss: 18.2202\n",
            "Epoch 11/50, Loss: 19.5924\n",
            "Epoch 12/50, Loss: 19.6673\n",
            "Epoch 13/50, Loss: 19.4071\n",
            "Epoch 14/50, Loss: 15.7702\n",
            "Epoch 15/50, Loss: 17.4336\n",
            "Epoch 16/50, Loss: 17.9689\n",
            "Epoch 17/50, Loss: 20.6733\n",
            "Epoch 18/50, Loss: 16.7920\n",
            "Epoch 19/50, Loss: 15.0181\n",
            "Epoch 20/50, Loss: 13.8019\n",
            "Epoch 21/50, Loss: 13.3050\n",
            "Epoch 22/50, Loss: 12.9222\n",
            "Epoch 23/50, Loss: 13.4969\n",
            "Epoch 24/50, Loss: 11.6613\n",
            "Epoch 25/50, Loss: 10.9324\n",
            "Epoch 26/50, Loss: 12.2051\n",
            "Epoch 27/50, Loss: 13.1313\n",
            "Epoch 28/50, Loss: 10.1765\n",
            "Epoch 29/50, Loss: 11.4822\n",
            "Epoch 30/50, Loss: 10.1458\n",
            "Epoch 31/50, Loss: 9.8531\n",
            "Epoch 32/50, Loss: 9.5494\n",
            "Epoch 33/50, Loss: 9.4963\n",
            "Epoch 34/50, Loss: 9.3142\n",
            "Epoch 35/50, Loss: 11.1705\n",
            "Epoch 36/50, Loss: 9.1529\n",
            "Epoch 37/50, Loss: 9.2697\n",
            "Epoch 38/50, Loss: 9.4430\n",
            "Epoch 39/50, Loss: 9.4033\n",
            "Epoch 40/50, Loss: 7.9733\n",
            "Epoch 41/50, Loss: 8.6127\n",
            "Epoch 42/50, Loss: 7.8749\n",
            "Epoch 43/50, Loss: 11.5185\n",
            "Epoch 44/50, Loss: 8.6069\n",
            "Epoch 45/50, Loss: 7.5176\n",
            "Epoch 46/50, Loss: 7.0042\n",
            "Epoch 47/50, Loss: 7.2231\n",
            "Epoch 48/50, Loss: 8.6078\n",
            "Epoch 49/50, Loss: 9.8111\n",
            "Epoch 50/50, Loss: 8.1004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == data.y).sum().item()\n",
        "            total += data.y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Load test dataset\n",
        "test_dataset_path = os.path.join(dataset_path, 'Testing')\n",
        "test_dataset = CurrencyGraphDataset(root=test_dataset_path)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "accuracy = evaluate(model, test_loader)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQSQL8PwsWtD",
        "outputId": "50d37bdb-bc1d-47d2-df9c-1d37e43103a6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Load a sample image\n",
        "sample_image_path = '/content/drive/MyDrive/Dataset4/Training/Fake/2.jpg'  # Replace with the path to your sample image\n",
        "image = cv2.imread(sample_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Preprocess the image and create the graph\n",
        "G, keypoints, descriptors = computeORBGraph(image)\n",
        "\n",
        "if G is None:\n",
        "    print(\"No keypoints detected in the sample image.\")\n",
        "else:\n",
        "    # Convert graph to PyTorch Geometric format\n",
        "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
        "    x = torch.tensor(np.array([G.nodes[i]['descriptor'] for i in G.nodes]), dtype=torch.float)\n",
        "    data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "    # Move data to the appropriate device (GPU if available)\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Make prediction with the trained model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1).item()\n",
        "\n",
        "    # Interpret the prediction\n",
        "    if pred == 0:\n",
        "        prediction_label = \"Real\"\n",
        "    else:\n",
        "        prediction_label = \"Fake\"\n",
        "\n",
        "    print(f\"Prediction for sample image: {prediction_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwMKGc0cyekl",
        "outputId": "4a8c262f-89ac-44ee-d390-a3ee1a4f96c8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sample image: Fake\n"
          ]
        }
      ]
    }
  ]
}